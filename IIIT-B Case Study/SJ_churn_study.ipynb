{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_df_base=pd.read_csv('telecom_churn_data.csv', encoding='iso-8859-1')\n",
    "telecom_plot_base=telecom_df_base.reset_index()\n",
    "master_df=telecom_df_base.copy()\n",
    "print(telecom_df_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_na_estimator_grph(data_f,limit_val=None,graphical=False,size=(None,None)):\n",
    "    \"\"\"will return the % amount of null in data frame\n",
    "       df: panda.DataFrame\n",
    "       limit_val= (default=None) threshold value, example if limit_val=7, the estimator will return na with >=7\n",
    "    \"\"\"\n",
    "    df=data_f.copy()\n",
    "    est_ser=est_ser= (round(df.isna().sum()/len(df.index)*100,2)).sort_values(ascending=False)\n",
    "    if limit_val!=None:\n",
    "        est_ser= est_ser[est_ser>=limit_val]\n",
    "    if graphical==True:\n",
    "        df=pd.DataFrame(est_ser).reset_index()\n",
    "        plt.figure(figsize=size)\n",
    "        plt.xticks(rotation=90)\n",
    "        fig=sns.barplot(data=df,x='index',y=0)\n",
    "        fig.set_ylabel('Percentage')\n",
    "        return fig\n",
    "    else:\n",
    "        return est_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_structure(df,return_tuple=False):\n",
    "    \"\"\"It will return the structure of dataframe or columns tuple as list\n",
    "    out: tuple (non-num,num,month_6,month_7,month_8,month_9)\n",
    "       : datafram ->structuring the complete dataset bifurcation\n",
    "    \"\"\"\n",
    "    df_col=df.columns\n",
    "    non_num_col=df.describe(include=['object']).columns\n",
    "    num_col=df_col.difference(non_num_col)\n",
    "    data_col_month=[x for x in df_col if re.search('_[0-9]$',x)!=None]\n",
    "    col_9=[x for x in df_col if re.search('_9',x)!=None]\n",
    "    col_8=[x for x in df_col if re.search('_8',x)!=None]\n",
    "    col_7=[x for x in df_col if re.search('_7',x)!=None]\n",
    "    col_6=[x for x in df_col if re.search('_6',x)!=None]\n",
    "    col_9_n=[x for x in num_col if re.search('_9',x)!=None]\n",
    "    col_8_n=[x for x in num_col if re.search('_8',x)!=None]\n",
    "    col_7_n=[x for x in num_col if re.search('_7',x)!=None]\n",
    "    col_6_n=[x for x in num_col if re.search('_6',x)!=None]\n",
    "    \n",
    "    if return_tuple==True:\n",
    "        return non_num_col.tolist(),num_col.tolist(),col_6,col_7,col_8,col_9\n",
    "    else:\n",
    "        result=pd.DataFrame({'Month 6':[abs(len(col_6_n)-len(col_6)),len(col_6_n)],\n",
    "                             'Month 7':[abs(len(col_7_n)-len(col_7)),len(col_7_n)],\n",
    "                             'Month 8':[abs(len(col_8_n)-len(col_8)),len(col_8_n)],\n",
    "                             'Month 9':[abs(len(col_9_n)-len(col_9)),len(col_9_n)]\n",
    "                    },index=['Non-Numeric','Numeric'])\n",
    "        result['Common']=[len(non_num_col)-(result.loc['Non-Numeric'].sum()),len(num_col)-(result.iloc[1,:].sum())]\n",
    "        result['Total']=[result.loc['Non-Numeric'].sum(),result.loc['Numeric'].sum()]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss(df_old,df_new):\n",
    "    \"\"\"will be calculating the data loss been made in the dataframe\"\"\"\n",
    "    df=pd.DataFrame({'Col loss':round(100*((len(df_old.columns)-len(df_new.columns))/len(df_old.columns)),2),\n",
    "                    'Row loss':round(100*((len(df_old.index)-len(df_new.index))/len(df_old.index)),2),\n",
    "                    'Data Retained':round(100*(len(df_new.columns)*len(df_new.index))/(len(df_old.columns)*len(df_old.index)),2)},index=['Percentage'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_variance_estimator(dataFrame,graphical=False,size=(None,None),graph_filter_limit_max=0):\n",
    "    variance_graph={}\n",
    "    for i in range(0,len(dataFrame.columns)):\n",
    "        variance_graph[dataFrame.columns[i]]=len(dataFrame.loc[:,dataFrame.columns[i]].unique())\n",
    "    variance_graph_df=pd.DataFrame({'var':list(variance_graph.keys()),'count':list(variance_graph.values())})\n",
    "    if graphical==True:\n",
    "        plt.figure(figsize=size)\n",
    "        plt.xticks(rotation=90)\n",
    "        text_title='Value Variance Graph < '+str(graph_filter_limit_max)\n",
    "        plt.title(text_title)\n",
    "        fig=sns.barplot(x='var',y='count',data=variance_graph_df[variance_graph_df['count']<graph_filter_limit_max].sort_values(by='count',ascending=True))\n",
    "        return fig\n",
    "    else:\n",
    "        return variance_graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An overview of data points and it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telecom_df_base.info())\n",
    "telecom_df_base.iloc[:,1:20].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review and fix structural error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correcting naming convention for some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_df_base.rename(columns={'jun_vbc_3g':'vbc_3g_6','jul_vbc_3g':'vbc_3g_7','aug_vbc_3g':'vbc_3g_8','sep_vbc_3g':'vbc_3g_9'},inplace=True)\n",
    "telecom_df_base[['vbc_3g_6','vbc_3g_7','vbc_3g_8','vbc_3g_9']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_num_col,num_col,col_6,col_7,col_8,col_9=data_set_structure(telecom_df_base,return_tuple=True)\n",
    "data_set_structure(telecom_df_base).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring null/na in data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring data points variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_graph_df=val_variance_estimator(telecom_df_base)\n",
    "val_variance_estimator(telecom_df_base,True,(15,3),graph_filter_limit_max=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping columns not having much information to add to analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisiting the data which don't have variance equal to 1 or 2\n",
    "variance_graph_df[variance_graph_df['count']<=2]['var']\n",
    "for i in variance_graph_df[variance_graph_df['count']<=2]['var']:\n",
    "    print(i,\" :\",telecom_df_base.loc[:,i].unique())\n",
    "drop_col=list(variance_graph_df[variance_graph_df['count']<=2]['var'])\n",
    "#Dropping columns with just 2 values\n",
    "print(\"As the value of these columns just have 2 values, which is not adding any information, we are going to drop them. As imputing them doesn't make sense\")\n",
    "telecom_df_base.drop(columns=drop_col,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loss(master_df,telecom_df_base))\n",
    "data_set_structure(telecom_df_base).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking null or na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_na_estimator_grph(telecom_df_base,5,graphical=True,size=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imputing features important of modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As some columns will be used in analysis and the value range is only between 0,1,na, we are going to impute them with a new class i.e. -1 for na\n",
    "\n",
    "for i in variance_graph_df.loc[(variance_graph_df['count']==3)]['var']:\n",
    "    print(i,\" :\",telecom_df_base.loc[:,i].unique())\n",
    "impute_col=list(variance_graph_df[variance_graph_df['count']==3]['var'])\n",
    "\n",
    "print(\"Imputing a new category of -1 reprsenting a miss\")\n",
    "\n",
    "telecom_df_base[impute_col]=telecom_df_base[impute_col].fillna(-1)\n",
    "impute_col=['av_rech_amt_data_6','av_rech_amt_data_7','av_rech_amt_data_8','av_rech_amt_data_9',\n",
    "            'total_rech_data_6','total_rech_data_7','total_rech_data_8','total_rech_data_9',\n",
    "            'max_rech_data_6','max_rech_data_7','max_rech_data_8','max_rech_data_9']\n",
    "\n",
    "print(\"Imputing 0 for missing values\")\n",
    "telecom_df_base[impute_col]=telecom_df_base[impute_col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_na_estimator_grph(telecom_df_base,5,graphical=True,size=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_df_base[impute_col].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating High value customer filter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_filter_col=['total_rech_amt_6','total_rech_data_6','total_rech_amt_7','total_rech_data_7',\n",
    "'total_rech_amt_8','total_rech_data_8','total_rech_amt_9','total_rech_data_9']\n",
    "#hv_filter_col=['total_rech_amt_6','total_rech_data_6','total_rech_num_6','total_rech_num_7','total_rech_amt_7','total_rech_data_7','total_rech_num_8','total_rech_amt_8','total_rech_data_8','total_rech_num_9','total_rech_amt_9','total_rech_data_9']\n",
    "print(\"PRE-Computation: analysis for na/null\\n\",telecom_df_base[hv_filter_col].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering high value customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Filtering high value customers\")\n",
    "telecom_df_base['total_month_rech_6']=telecom_df_base.loc[:,hv_filter_col[0]]+telecom_df_base.loc[:,hv_filter_col[1]]\n",
    "telecom_df_base['total_month_rech_7']=telecom_df_base.loc[:,hv_filter_col[2]]+telecom_df_base.loc[:,hv_filter_col[3]]\n",
    "telecom_df_base['total_month_rech_8']=telecom_df_base.loc[:,hv_filter_col[4]]+telecom_df_base.loc[:,hv_filter_col[5]]\n",
    "telecom_df_base['total_month_rech_9']=telecom_df_base.loc[:,hv_filter_col[6]]+telecom_df_base.loc[:,hv_filter_col[7]]\n",
    "#telecom_df_base.to_csv('prehighvalue.csv')\n",
    "hv_percentile=(telecom_df_base.loc[:,hv_filter_col[0]]+telecom_df_base.loc[:,hv_filter_col[3]]).quantile(.7)\n",
    "telecom_df_base=telecom_df_base[telecom_df_base.loc[:,hv_filter_col[0]]+telecom_df_base.loc[:,hv_filter_col[3]]>hv_percentile]\n",
    "telecom_df_base.reset_index(inplace=True)\n",
    "print(\"Dimension of High value customer dataset: \",telecom_df_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting churn=1 not-churn=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_df_base['churn']=((telecom_df_base['total_ic_mou_9']+telecom_df_base['total_og_mou_9']>0) & (telecom_df_base['vol_2g_mb_9']+telecom_df_base['vol_3g_mb_9'])>0)\n",
    "telecom_df_base.loc[:,'churn'].replace({True:1,False:0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(x=[len(telecom_df_base[telecom_df_base['churn']==1]),len(telecom_df_base[telecom_df_base['churn']==0])],labels=['Churned','Not Churned'],autopct='%1.1f%%',colors=['yellowgreen', 'lightcoral'],explode=(.1,0))\n",
    "plt.axis('equal')\n",
    "plt.title('Telcom Churn Rate',fontsize=18,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seprating Prediction and Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_col,num_col,col_6,col_7,col_8,col_9=data_set_structure(telecom_df_base,return_tuple=True)\n",
    "telecom_data_analysis=telecom_df_base.drop(columns=col_9,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=null_na_estimator_grph(telecom_data_analysis,limit_val=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping all data with some null the dimesion reduction is = (29999, 163) -> (29999, 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_data_analysis.drop(columns=drop_col.index,axis=1,inplace=True)\n",
    "print(telecom_data_analysis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
