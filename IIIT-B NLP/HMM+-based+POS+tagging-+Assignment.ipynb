{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import time\n",
    "from nltk.tokenize import word_tokenize\n",
    "from functools import reduce\n",
    "import random\n",
    "import pdb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting Treebank dataset into train & validation set in ration of 95:5 %\n",
    "train_set, validation_set = train_test_split(nltk_data,train_size=.95,test_size=0.05,random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size-> nltk: 3914, Training:3718, Validation: 196\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size-> nltk: {}, Training:{}, Validation: {}\".format(len(nltk_data),len(train_set),len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length-> Vocabulary: 12088, Tags: 12\n",
      "Available Tags->  {'DET', 'CONJ', 'PRT', '.', 'NOUN', 'X', 'ADP', 'ADJ', 'ADV', 'VERB', 'NUM', 'PRON'}\n"
     ]
    }
   ],
   "source": [
    "tagged_train_set=[tup for set in train_set for tup in set]\n",
    "# Extracging vocabulary and respective Tags sperately\n",
    "vocabulary=(set([v[0] for v in tagged_train_set]))\n",
    "tags=set(v[1] for v in tagged_train_set)\n",
    "print(\"Length-> Vocabulary: {}, Tags: {}\".format(len(vocabulary),len(tags)))\n",
    "print(\"Available Tags-> \",tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = tagged_train_set):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag = tagged_train_set):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_matrix\n",
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DET     0.173507\n",
       "CONJ    0.058015\n",
       "PRT     0.002515\n",
       ".       0.091783\n",
       "NOUN    0.222452\n",
       "X       0.027211\n",
       "ADP     0.091334\n",
       "ADJ     0.043197\n",
       "ADV     0.053345\n",
       "VERB    0.089807\n",
       "NUM     0.081275\n",
       "PRON    0.065469\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = tagged_train_set,backoff=[]):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "#         state_max=0.0\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        state_max = None\n",
    "#         print(str(pmax)+' '+word)\n",
    "        if pmax==0.0:\n",
    "#             pdb.set_trace()\n",
    "            linker=backoff.copy()\n",
    "            while linker!=[]:\n",
    "                if state_max==None:\n",
    "                    state_max=linker.pop()([word])[0][1]\n",
    "                else:\n",
    "                    linker.clear()\n",
    "#                 print(str(pmax)+' '+word)\n",
    "#         pdb.set_trace()\n",
    "        # getting state for which probability is maximum\n",
    "        if state_max==None:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Viterbi(words, train_bag = tagged_train_set,backoff=[]):\n",
    "#     state = []\n",
    "#     T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "#     for key, word in enumerate(words):\n",
    "#         #initialise list of probability column for a given observation\n",
    "#         p = [] \n",
    "# #         state_max=0.0\n",
    "#         for tag in T:\n",
    "#             if key == 0:\n",
    "#                 transition_p = tags_df.loc['.', tag]\n",
    "#             else:\n",
    "#                 transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "#             # compute emission and state probabilities\n",
    "#             emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "#             state_probability = emission_p * transition_p    \n",
    "#             p.append(state_probability)\n",
    "#         pmax = max(p)\n",
    "#         state_max = T[p.index(pmax)] \n",
    "# #         print(str(pmax)+' '+word)\n",
    "#         if pmax==0.0:\n",
    "#             pdb.set_trace()\n",
    "#             if len(backoff)!=0:\n",
    "# #                 if backoff[0].__name__=='cardinal_tagger':\n",
    "#                 state_max=backoff[0]([word])[0][1]\n",
    "#                     if state_max==None and :\n",
    "#                         status=backoff[0]([word])\n",
    "# #                 print(str(pmax)+' '+word)\n",
    "# #         pdb.set_trace()\n",
    "#         # getting state for which probability is maximum\n",
    "#         if state_max==None:\n",
    "#             state_max = T[p.index(pmax)] \n",
    "#         state.append(state_max)\n",
    "#     return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Viterbi(words, train_bag = tagged_train_set,backoff=[]):\n",
    "#     state = []\n",
    "#     T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "#     for key, word in enumerate(words):\n",
    "#         #initialise list of probability column for a given observation\n",
    "#         if (re.search('^[A-Z]+([a-z]{1})?\\.?$',word) or re.search('.*[0-9]+.*',word))==None:\n",
    "#             p = [] \n",
    "#             for tag in T:\n",
    "#                 if key == 0:\n",
    "#                     transition_p = tags_df.loc['.', tag]\n",
    "#                 else:\n",
    "#                     transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "#                 # compute emission and state probabilities\n",
    "#                 emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "#                 state_probability = emission_p * transition_p    \n",
    "#                 p.append(state_probability)\n",
    "\n",
    "#             pmax = max(p)\n",
    "#     #         pdb.set_trace()\n",
    "#             # getting state for which probability is maximum\n",
    "#             state_max = T[p.index(pmax)] \n",
    "#         else:\n",
    "#             state_max=cardinal_tagger([word])[0][1]\n",
    "#         state.append(state_max)\n",
    "#     return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(1234)\n",
    "# # choose random 5 sents\n",
    "# rndom = [random.randint(1,len(validation_set)) for x in range(5)]\n",
    "# print(rndom)\n",
    "# validation_run = [validation_set[i] for i in rndom]\n",
    "# validation_run_base = [tup for sent in validation_run for tup in sent]\n",
    "# print(len(validation_run_base))\n",
    "# sum([len(v) for v in validation_run])\n",
    "# sum([len(v) for v in validation_set])\n",
    "len(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " 'far',\n",
       " ',',\n",
       " 'Mrs.',\n",
       " 'Hills',\n",
       " 'has',\n",
       " \"n't\",\n",
       " 'deemed',\n",
       " 'any',\n",
       " 'cases',\n",
       " 'bad',\n",
       " 'enough',\n",
       " '*-1',\n",
       " 'to',\n",
       " 'merit',\n",
       " 'an',\n",
       " 'accelerated',\n",
       " 'investigation',\n",
       " 'under',\n",
       " 'the',\n",
       " 'so-called',\n",
       " 'special',\n",
       " '301',\n",
       " 'provision',\n",
       " 'of',\n",
       " 'the',\n",
       " 'act',\n",
       " '.',\n",
       " 'Despite',\n",
       " 'the',\n",
       " 'strong',\n",
       " 'evidence',\n",
       " 'against',\n",
       " 'Mrs.',\n",
       " 'Yeargin',\n",
       " ',',\n",
       " 'popular',\n",
       " 'sentiment',\n",
       " '*ICH*-1',\n",
       " 'was',\n",
       " 'so',\n",
       " 'strong',\n",
       " '*ICH*-3',\n",
       " 'in',\n",
       " 'her',\n",
       " 'favor',\n",
       " ',',\n",
       " 'Mrs.',\n",
       " 'Ward',\n",
       " 'says',\n",
       " '0',\n",
       " '*T*-2',\n",
       " ',',\n",
       " 'that',\n",
       " '``',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'afraid',\n",
       " '0',\n",
       " 'a',\n",
       " 'jury',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'convicted',\n",
       " 'her',\n",
       " '.',\n",
       " 'In',\n",
       " 'CAT',\n",
       " 'sections',\n",
       " 'where',\n",
       " 'students',\n",
       " \"'\",\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'two-letter',\n",
       " 'consonant',\n",
       " 'sounds',\n",
       " 'is',\n",
       " 'tested',\n",
       " '*-1',\n",
       " '*T*-2',\n",
       " ',',\n",
       " 'the',\n",
       " 'authors',\n",
       " 'noted',\n",
       " 'that',\n",
       " 'Scoring',\n",
       " 'High',\n",
       " 'concentrated',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'sounds',\n",
       " 'that',\n",
       " 'the',\n",
       " 'test',\n",
       " 'does',\n",
       " '*?*',\n",
       " '*T*-4',\n",
       " '--',\n",
       " 'to',\n",
       " 'the',\n",
       " 'exclusion',\n",
       " 'of',\n",
       " 'other',\n",
       " 'sounds',\n",
       " 'that',\n",
       " 'fifth',\n",
       " 'graders',\n",
       " 'should',\n",
       " 'know',\n",
       " '*T*-3',\n",
       " '.',\n",
       " '*',\n",
       " 'Guaranteed',\n",
       " '*-1',\n",
       " 'by',\n",
       " 'Svenska',\n",
       " 'Handelsbanken',\n",
       " '.',\n",
       " 'A',\n",
       " 'voice',\n",
       " 'says',\n",
       " ',',\n",
       " '``',\n",
       " \"C'mon\",\n",
       " ',',\n",
       " 'now',\n",
       " ',',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'you',\n",
       " 'have',\n",
       " 'boyfriends',\n",
       " '?',\n",
       " \"''\",\n",
       " '*-1',\n",
       " 'To',\n",
       " 'keep',\n",
       " 'program-trading',\n",
       " 'units',\n",
       " 'profitable',\n",
       " 'in',\n",
       " 'the',\n",
       " 'eyes',\n",
       " 'of',\n",
       " 'senior',\n",
       " 'brokerage',\n",
       " 'executives',\n",
       " ',',\n",
       " 'traders',\n",
       " 'must',\n",
       " 'seize',\n",
       " 'every',\n",
       " 'opportunity',\n",
       " '0',\n",
       " 'their',\n",
       " 'computers',\n",
       " 'find',\n",
       " '*T*-2',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Einhorn',\n",
       " 'of',\n",
       " 'Goldman',\n",
       " 'Sachs',\n",
       " 'estimates',\n",
       " '0',\n",
       " 'the',\n",
       " 'stock',\n",
       " 'market',\n",
       " 'will',\n",
       " 'deliver',\n",
       " 'a',\n",
       " '12',\n",
       " '%',\n",
       " 'to',\n",
       " '15',\n",
       " '%',\n",
       " '*U*',\n",
       " 'total',\n",
       " 'return',\n",
       " 'from',\n",
       " 'appreciation',\n",
       " 'and',\n",
       " 'dividends',\n",
       " '*ICH*-1',\n",
       " 'over',\n",
       " 'the',\n",
       " 'next',\n",
       " '12',\n",
       " 'months',\n",
       " '--',\n",
       " 'vs.',\n",
       " 'a',\n",
       " '``',\n",
       " 'cash',\n",
       " 'rate',\n",
       " 'of',\n",
       " 'return',\n",
       " \"''\",\n",
       " 'of',\n",
       " 'perhaps',\n",
       " '7',\n",
       " '%',\n",
       " 'or',\n",
       " '8',\n",
       " '%',\n",
       " '*U*',\n",
       " 'if',\n",
       " 'dividend',\n",
       " 'growth',\n",
       " 'is',\n",
       " 'weak',\n",
       " '.',\n",
       " 'A',\n",
       " 'Shearson',\n",
       " 'spokesman',\n",
       " 'said',\n",
       " '0',\n",
       " 'the',\n",
       " 'firm',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'worried',\n",
       " '.',\n",
       " '``',\n",
       " 'Cray',\n",
       " 'Computer',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'concept',\n",
       " 'stock',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'said',\n",
       " '*T*-1',\n",
       " '.',\n",
       " 'A',\n",
       " 'final',\n",
       " 'modification',\n",
       " '*ICH*-1',\n",
       " 'was',\n",
       " 'made',\n",
       " '*-130',\n",
       " 'to',\n",
       " 'the',\n",
       " 'five-point',\n",
       " 'opening',\n",
       " 'limit',\n",
       " 'for',\n",
       " 'the',\n",
       " 'contract',\n",
       " '.']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(validation_set)) for x in range(10)]\n",
    "\n",
    "# list of sents\n",
    "validation_run = [validation_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "validation_run_base = [tup for sent in validation_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "validation_tagged_words = [tup[0] for sent in validation_run for tup in sent]\n",
    "validation_tagged_words\n",
    "# validation_run_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_run_base=[tup for sent in validation_set for tup in sent] # it's a list of tuple with WORD and TAG\n",
    "validation_tagged_words = [tup[0] for sent in validation_set for tup in sent] # list of TAGS\n",
    "# # validation_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(validation_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.89800000190735\n",
      "257 257\n",
      "('So', 'ADV') ('So', 'ADP')\n"
     ]
    }
   ],
   "source": [
    "print(\"Time taken in seconds: \", difference)\n",
    "# print(tagged_seq)\n",
    "print(len(tagged_seq),len(validation_run_base))\n",
    "print(tagged_seq[0],validation_run_base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9027237354085603\n"
     ]
    }
   ],
   "source": [
    "check = [i for i, j in zip(tagged_seq, validation_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "# print(len(check))\n",
    "print(accuracy)\n",
    "incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, validation_run_base)) if j[0]!=j[1]]\n",
    "# 0.9014084507042254\n",
    "# 0.9172749391727494\n",
    "# 0.9221411192214112\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('So', 'ADV'), ('So', 'ADP')),\n",
       " (('deemed', 'DET'), ('deemed', 'VERB')),\n",
       " (('enough', 'ADJ'), ('enough', 'ADV')),\n",
       " (('merit', 'NOUN'), ('merit', 'VERB')),\n",
       " (('accelerated', 'ADJ'), ('accelerated', 'VERB')),\n",
       " (('301', 'DET'), ('301', 'NUM')),\n",
       " (('favor', 'VERB'), ('favor', 'NOUN')),\n",
       " (('that', 'DET'), ('that', 'ADP')),\n",
       " (('two-letter', 'DET'), ('two-letter', 'ADJ')),\n",
       " (('consonant', 'DET'), ('consonant', 'ADJ')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('to', 'PRT'), ('to', 'ADP')),\n",
       " (('exclusion', 'DET'), ('exclusion', 'NOUN')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('Handelsbanken', 'DET'), ('Handelsbanken', 'NOUN')),\n",
       " ((\"C'mon\", 'DET'), (\"C'mon\", 'VERB')),\n",
       " (('boyfriends', 'DET'), ('boyfriends', 'NOUN')),\n",
       " (('estimates', 'NOUN'), ('estimates', 'VERB')),\n",
       " (('total', 'VERB'), ('total', 'NOUN')),\n",
       " (('vs.', 'CONJ'), ('vs.', 'ADP')),\n",
       " (('%', 'NOUN'), ('%', 'ADJ')),\n",
       " (('modification', 'DET'), ('modification', 'NOUN')),\n",
       " (('*-130', 'DET'), ('*-130', 'X')),\n",
       " (('opening', 'NOUN'), ('opening', 'VERB'))]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases\n",
    "# validation_tagged_words\n",
    "# Viterbi(validation_tagged_words[1:40],backoff=[cardinal_tagger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12088   1820\n",
      "Vocabulary which is not part of Training Set but part of Validation Set\n",
      "Total Unknown words: 320, sample->['parts-engineering', 'pride', 'disaster-assistance']\n",
      "Vocabulary which is not part of Training Set but part of Validation Set\n",
      "Total common words: 1500, sample->['eliminated', 'fall', 'Kalipharma']\n"
     ]
    }
   ],
   "source": [
    "tagged_words_validation=[tup for ls in validation_set for tup in ls]\n",
    "vocabulary_validation=set([t[0] for t in tagged_words_validation])\n",
    "\n",
    "print(len(vocabulary),' ',len(vocabulary_validation))\n",
    "print(\"Vocabulary which is not part of Training Set but part of Validation Set\")\n",
    "UnknownWords=list(vocabulary_validation-vocabulary)\n",
    "CommonWords=list(vocabulary_validation.intersection(vocabulary))\n",
    "print(\"Total Unknown words: {}, sample->{}\".format(len(UnknownWords),UnknownWords[0:3]))\n",
    "print(\"Vocabulary which is not part of Training Set but part of Validation Set\")\n",
    "print(\"Total common words: {}, sample->{}\".format(len(CommonWords),CommonWords[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parts-engineering',\n",
       " 'pride',\n",
       " 'disaster-assistance',\n",
       " 'vicissitudes',\n",
       " 'regulations',\n",
       " 'Baking',\n",
       " 'Norwegian',\n",
       " 'double-A',\n",
       " 'Advice',\n",
       " 'deliberating',\n",
       " 'rendering',\n",
       " 'ECONOMIC',\n",
       " 'forecasting',\n",
       " 'dismayed',\n",
       " 'tows',\n",
       " '7.8',\n",
       " 'administer',\n",
       " 'disapproval',\n",
       " '*T*-176',\n",
       " 'responds',\n",
       " 'dusty',\n",
       " 'Nine',\n",
       " '2.95',\n",
       " 'sacrificing',\n",
       " 'sketching',\n",
       " 'disapproved',\n",
       " 'English-speaking',\n",
       " 'inevitable',\n",
       " 'boots',\n",
       " 'Four',\n",
       " 'CERTIFICATES',\n",
       " 'mentioned',\n",
       " 'retiring',\n",
       " 'Majority',\n",
       " 'tags',\n",
       " 'BRIEFS',\n",
       " 'timing',\n",
       " 'injuring',\n",
       " 'rectified',\n",
       " 'commanded',\n",
       " 'Huntington',\n",
       " 'newsstand',\n",
       " '6.03',\n",
       " 'Ian',\n",
       " 'illustrates',\n",
       " 'vague',\n",
       " 'Heiwado',\n",
       " '70.2',\n",
       " 'Alurralde',\n",
       " 'Riviera',\n",
       " 'diagnosed',\n",
       " 'APPEARS',\n",
       " 'percent',\n",
       " 'resumption',\n",
       " 'skirmishes',\n",
       " 'insider',\n",
       " 'contractors',\n",
       " 'deck',\n",
       " 'TRIMMING',\n",
       " 'modification',\n",
       " \"C'mon\",\n",
       " 'Cathedral',\n",
       " '0.28',\n",
       " 'Tailors',\n",
       " 'odd-year',\n",
       " 'riding',\n",
       " 'U.S.-Japan',\n",
       " 'RBC',\n",
       " 'Heatherington',\n",
       " 'freeway',\n",
       " 'alike',\n",
       " 'Andean',\n",
       " 'yearly',\n",
       " '301',\n",
       " 'injecting',\n",
       " 'fingers',\n",
       " 'inquiring',\n",
       " 'accordance',\n",
       " '3.55',\n",
       " 'Continuing',\n",
       " 'Short',\n",
       " 'humans',\n",
       " 'Dale',\n",
       " 'Jan.',\n",
       " 'Encouraged',\n",
       " 'uncanny',\n",
       " 'plugged',\n",
       " '9.3',\n",
       " 'corn-buying',\n",
       " 'McLeod',\n",
       " \"'80s\",\n",
       " 'reflection',\n",
       " 'citizen-sparked',\n",
       " 'sweaty',\n",
       " 'drop-in',\n",
       " 'pipeline',\n",
       " 'charging',\n",
       " 'GROWTH',\n",
       " 'Metal',\n",
       " 'launch-vehicle',\n",
       " 'designated',\n",
       " 'Consent',\n",
       " '*T*-140',\n",
       " 'lasted',\n",
       " 'Explorer',\n",
       " 'walking',\n",
       " 'sole',\n",
       " 'muzzling',\n",
       " 'middle-ground',\n",
       " '1.56',\n",
       " 'school-research',\n",
       " 'executive-office',\n",
       " 'stacking',\n",
       " 'external',\n",
       " 'binge',\n",
       " 'Sumitomo',\n",
       " 'bell-ringing',\n",
       " 'Miguel',\n",
       " '4.875',\n",
       " 'usurp',\n",
       " 'campaigner',\n",
       " 'caustic',\n",
       " '133.7',\n",
       " 'equal-opportunity',\n",
       " 'consonant',\n",
       " 'seafood',\n",
       " 'approached',\n",
       " 'breathtaking',\n",
       " 'Greece',\n",
       " 'OF',\n",
       " 'three-quarters',\n",
       " '59.6',\n",
       " '131.01',\n",
       " 'shift',\n",
       " 'boyfriends',\n",
       " 'scaring',\n",
       " 'establish',\n",
       " 'concentrating',\n",
       " 'quitting',\n",
       " 'industrywide',\n",
       " 'tired',\n",
       " 'ambassadors',\n",
       " 'bottlenecks',\n",
       " 'sport-utility',\n",
       " 'soldiers',\n",
       " 'Signs',\n",
       " 'Commodities',\n",
       " 'Youths',\n",
       " 'deemed',\n",
       " 'ballots',\n",
       " 'Scotia',\n",
       " 'C.D.s',\n",
       " 'Domaine',\n",
       " 'queuing',\n",
       " 'Individual',\n",
       " 'circuit-board',\n",
       " 'spurns',\n",
       " 'less-serious',\n",
       " 'tie-breaking',\n",
       " 'comprehensive',\n",
       " 'shuttle',\n",
       " 'open-top',\n",
       " 'livelihood',\n",
       " 'accountants',\n",
       " 'Except',\n",
       " 'McAuley',\n",
       " 'Lead',\n",
       " 'enjoy',\n",
       " 'Value',\n",
       " 'recyclability',\n",
       " '12.09',\n",
       " 'mushy',\n",
       " '372.14',\n",
       " '*T*-246',\n",
       " 'Continental',\n",
       " 'trafficking',\n",
       " 'penny',\n",
       " 'oblivion',\n",
       " 'pains',\n",
       " 'appoint',\n",
       " 'unloaded',\n",
       " 'marrow',\n",
       " 'hoopla',\n",
       " '1.4',\n",
       " 'aspires',\n",
       " '960',\n",
       " 'accompany',\n",
       " 'transplantation',\n",
       " 'negotiable',\n",
       " 'fluent',\n",
       " 'la',\n",
       " '13.50',\n",
       " 'diabetes',\n",
       " 'Calif.-based',\n",
       " 'engines',\n",
       " '1.17',\n",
       " 'galling',\n",
       " 'quote',\n",
       " 'exit',\n",
       " 'FOREIGN',\n",
       " 'Ancient',\n",
       " 'vineyard',\n",
       " 'philosophy',\n",
       " '*T*-161',\n",
       " '609',\n",
       " '*T*-139',\n",
       " 'crunch',\n",
       " 'containers',\n",
       " 'rebuilding',\n",
       " 'disposed',\n",
       " 'leveling',\n",
       " 'Gringo',\n",
       " 'realestate',\n",
       " '692',\n",
       " 'Kathryn',\n",
       " 'F.H.',\n",
       " 'sewer',\n",
       " 'Pa',\n",
       " 'unsympathetic',\n",
       " 'lyrics',\n",
       " 'Rozell',\n",
       " 'bread',\n",
       " 'upper',\n",
       " 'softer',\n",
       " 'applicable',\n",
       " 'Trans',\n",
       " 'arbitrager',\n",
       " 'inauspicious',\n",
       " 'modems',\n",
       " 'warranties',\n",
       " 'anywhere',\n",
       " 'Revolution',\n",
       " 'abridging',\n",
       " 'Abbey',\n",
       " 'unlabeled',\n",
       " 'degenerative',\n",
       " 'round-trip',\n",
       " 'payable',\n",
       " 'motor-home',\n",
       " 'leaky',\n",
       " '*-130',\n",
       " 'disagreeable',\n",
       " 'carefree',\n",
       " 'prayer',\n",
       " 'unanimous',\n",
       " 'Unless',\n",
       " 'Fuentes',\n",
       " 'blames',\n",
       " 'drastic',\n",
       " '1637',\n",
       " 'Raymond',\n",
       " 'sue',\n",
       " 'robbed',\n",
       " 'broad-based',\n",
       " 'juvenile',\n",
       " '858,000',\n",
       " 'passers-by',\n",
       " 'blinks',\n",
       " '*T*-230',\n",
       " 'accrue',\n",
       " 'blood-cell',\n",
       " 'Everything',\n",
       " 'Areas',\n",
       " 'viewpoints',\n",
       " 'Handelsbanken',\n",
       " '51-year-old',\n",
       " 'Barbados',\n",
       " 'expendable',\n",
       " 'plaintive',\n",
       " 'favors',\n",
       " 'doctrine',\n",
       " 'Henderson',\n",
       " 'proscribes',\n",
       " 'restricts',\n",
       " 'pain',\n",
       " 'leather',\n",
       " 'recommendation',\n",
       " 'Mexican',\n",
       " 'trimming',\n",
       " 'sticky',\n",
       " 'stigma',\n",
       " 'Paso',\n",
       " 'weight',\n",
       " '50-state',\n",
       " 'heavy-duty',\n",
       " 'twisting',\n",
       " '18.3',\n",
       " 'piracy',\n",
       " 'Whip',\n",
       " 'imply',\n",
       " 'Behind',\n",
       " 'co-developers',\n",
       " 'unlikely',\n",
       " 'Overseas',\n",
       " 'exclusion',\n",
       " '94',\n",
       " 'differently',\n",
       " '129.91',\n",
       " 'Hayes',\n",
       " 'Andersson',\n",
       " 'TIRED',\n",
       " 'obvious',\n",
       " 'male-only',\n",
       " 'Left',\n",
       " 'attributes',\n",
       " 'published',\n",
       " '*-58',\n",
       " 'disregard',\n",
       " 'two-letter',\n",
       " 'assurance',\n",
       " 'Westminster',\n",
       " '8.06',\n",
       " 'three-digit',\n",
       " 'Dominion',\n",
       " 'high-minded',\n",
       " 'market-oriented',\n",
       " 'DEPOSIT',\n",
       " 'captivating',\n",
       " 'bang',\n",
       " 'angle']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UnknownWords\n",
    "\n",
    "#There are some subtle things which can be find which are misclassified by Viterbi algorithm like\n",
    "\n",
    "# Numbers-> ('3.19', 'ADV'), ('3.19', 'NUM'))\n",
    "# Wines/ Company Names -> Louisiana-Pacific, Antinori\n",
    "# Countries Names-> Africa, (('Clarence', 'ADV'), ('Clarence', 'NOUN')), (('American', 'ADJ'), ('American', 'NOUN')),\n",
    "# Salutation like Sr. Mr. Md.\n",
    "# Door Numbers/Flat--> 50-State, cary-3 etc.\n",
    "# Capitalization Rule--> ASSOCIATION, CIA etc.\n",
    "\n",
    "# We will handle numbers, Salutation, Capitalization, and Flat number via RegexpTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cardinal_tagger(word):\n",
    "    patterns = [\n",
    "    (r'^[aA-zZ].*[0-9]+','NOUN'),  #Flat/Door Number, Street Number\n",
    "    (r'[1-9].?[,\\/]?[0-9]*','NUM'),# Any Form of number non-0\n",
    "    (r'^(0|[*|-|$].*)','X'), #Any special form of number like *T* *a-767, 0\n",
    "    (r'^[0-9]+\\-[aA-zZ]*$','ADJ') #adjective like 100-megabytes 237-Seats\n",
    "    ]\n",
    "#     pdb.set_trace()\n",
    "    regextagger=nltk.RegexpTagger(patterns)\n",
    "    return regextagger.tag(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_morphological_tagger(word):\n",
    "    patterns = [\n",
    "    (r'^[A-Z]+([a-z]{1,2})?\\.?$','NOUN'),# Capitalization rule of English and Salutation\n",
    "    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'),\n",
    "    (r'[aA-zZ]+(\\'s|s)$', 'NOUN'),             # possessive nouns & plural nouns\n",
    "    (r'^[A-Z]{1}[a-z]*$','NOUN')\n",
    "    ]\n",
    "    print(\"Englis\")\n",
    "    regextagger=nltk.RegexpTagger(patterns)\n",
    "    status=regextagger.tag(word)\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cycles', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "print(cardinal_tagger(['cycles'],backoff=[english_morphological_tagger]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(validation_tagged_words,backoff=[cardinal_tagger])\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9105058365758755\n"
     ]
    }
   ],
   "source": [
    "check = [i for i, j in zip(tagged_seq, validation_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "# print(len(check))\n",
    "print(accuracy)\n",
    "incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, validation_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('So', 'ADV'), ('So', 'ADP')),\n",
       " (('deemed', 'DET'), ('deemed', 'VERB')),\n",
       " (('enough', 'ADJ'), ('enough', 'ADV')),\n",
       " (('merit', 'NOUN'), ('merit', 'VERB')),\n",
       " (('accelerated', 'ADJ'), ('accelerated', 'VERB')),\n",
       " (('favor', 'VERB'), ('favor', 'NOUN')),\n",
       " (('that', 'DET'), ('that', 'ADP')),\n",
       " (('two-letter', 'DET'), ('two-letter', 'ADJ')),\n",
       " (('consonant', 'DET'), ('consonant', 'ADJ')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('to', 'PRT'), ('to', 'ADP')),\n",
       " (('exclusion', 'DET'), ('exclusion', 'NOUN')),\n",
       " (('sounds', 'VERB'), ('sounds', 'NOUN')),\n",
       " (('Handelsbanken', 'DET'), ('Handelsbanken', 'NOUN')),\n",
       " ((\"C'mon\", 'DET'), (\"C'mon\", 'VERB')),\n",
       " (('boyfriends', 'DET'), ('boyfriends', 'NOUN')),\n",
       " (('estimates', 'NOUN'), ('estimates', 'VERB')),\n",
       " (('total', 'VERB'), ('total', 'NOUN')),\n",
       " (('vs.', 'CONJ'), ('vs.', 'ADP')),\n",
       " (('%', 'NOUN'), ('%', 'ADJ')),\n",
       " (('modification', 'DET'), ('modification', 'NOUN')),\n",
       " (('opening', 'NOUN'), ('opening', 'VERB'))]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-222-4272827202b2>(24)Viterbi()\n",
      "-> linker=backoff.copy()\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-899e0e6f99a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtagged_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mViterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_tagged_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbackoff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcardinal_tagger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menglish_morphological_tagger\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdifference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-222-4272827202b2>\u001b[0m in \u001b[0;36mViterbi\u001b[1;34m(words, train_bag, backoff)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpmax\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mlinker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackoff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlinker\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstate_max\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-222-4272827202b2>\u001b[0m in \u001b[0;36mViterbi\u001b[1;34m(words, train_bag, backoff)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpmax\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mpdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mlinker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackoff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlinker\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mstate_max\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\envs\\DS_3_6\\lib\\bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[1;34m(self, frame, event, arg)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;31m# None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'line'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'call'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\envs\\DS_3_6\\lib\\bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(validation_tagged_words,backoff=[cardinal_tagger,english_morphological_tagger])\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [i for i, j in zip(tagged_seq, validation_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "# print(len(check))\n",
    "print(accuracy)\n",
    "incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, validation_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.fullmatch('[0-9].?[0-9]*','600,000')\n",
    "\n",
    "\n",
    "# (('1980s', 'NOUN'), ('1980s', 'NUM')),\n",
    "# (('190-point', 'NUM'), ('190-point', 'ADJ')),\n",
    "#   (('237-seat', 'NUM'), ('237-seat', 'ADJ')),\n",
    "#     (('100-megabyte', 'NUM'), ('100-megabyte', 'ADJ')),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'[1-9].?[,\\/]?[0-9]*','NUM'),\n",
    "    (r'^(0|[*|-|$].*)','X')\n",
    "    ]\n",
    "regextagger=nltk.RegexpTagger(patterns)\n",
    "regextagger.tag(['C-90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (NE U.S./NNP)\n",
      "  is/VBZ\n",
      "  one/CD\n",
      "  of/IN\n",
      "  the/DT\n",
      "  few/JJ\n",
      "  industrialized/VBN\n",
      "  nations/NNS\n",
      "  that/WDT\n",
      "  *T*-7/-NONE-\n",
      "  does/VBZ\n",
      "  n't/RB\n",
      "  have/VB\n",
      "  a/DT\n",
      "  higher/JJR\n",
      "  standard/NN\n",
      "  of/IN\n",
      "  regulation/NN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  smooth/JJ\n",
      "  ,/,\n",
      "  needle-like/JJ\n",
      "  fibers/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  crocidolite/NN\n",
      "  that/WDT\n",
      "  *T*-1/-NONE-\n",
      "  are/VBP\n",
      "  classified/VBN\n",
      "  *-5/-NONE-\n",
      "  as/IN\n",
      "  amphobiles/NNS\n",
      "  ,/,\n",
      "  according/VBG\n",
      "  to/TO\n",
      "  (NE Brooke/NNP)\n",
      "  T./NNP\n",
      "  Mossman/NNP\n",
      "  ,/,\n",
      "  a/DT\n",
      "  professor/NN\n",
      "  of/IN\n",
      "  pathlogy/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (NE University/NNP)\n",
      "  of/IN\n",
      "  (NE Vermont/NNP College/NNP)\n",
      "  of/IN\n",
      "  (NE Medicine/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "sent=nltk.corpus.treebank.tagged_sents()[22]\n",
    "print(nltk.ne_chunk(sent, binary=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\jaisa05\\\\AppData\\\\Local\\\\Temp\\\\tmpcsvhg8v6.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\envs\\DS_3_6\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\envs\\DS_3_6\\lib\\site-packages\\nltk\\tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m                             \u001b[1;34m'-q -dEPSCrop -sDEVICE=png16m -r90 -dTextAlphaBits=4 -dGraphicsAlphaBits=4 -dSAFER -dBATCH -dNOPAUSE -sOutputFile={0:} {1:}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                             .format(out_path, in_path).split())\n\u001b[1;32m--> 733\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\jaisa05\\\\AppData\\\\Local\\\\Temp\\\\tmpcsvhg8v6.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [('resumption', 'DET')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.ne_chunk([incorrect_tagged_cases[0][0]])\n",
    "# nltk.ne_chunk_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=nltk.ne_chunk(nltk.corpus.treebank.tagged_sents()[0])\n",
    "tree.leaves()\n",
    "# nltk.ne_chunk(.tagged_sents()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Test File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readinig the Test File\n",
    "with open('./Test_sentences.txt','r') as f:\n",
    "    lines=f.readlines()\n",
    "# joining lines to form a single string\n",
    "test_string=reduce(lambda x,y: x+ ' '+y,lines)\n",
    "test_string=test_string.replace('\\n','') #removing extra new line characters\n",
    "test_string=test_string.strip() #strip white spaces\n",
    "# Generating word tokens from sentence\n",
    "test_tokens=word_tokenize(test_string)\n",
    "test_set=nltk.pos_tag(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Google', 'NNP'), ('and', 'CC'), ('Twitter', 'NNP'), ('made', 'VBD'), ('a', 'DT'), ('deal', 'NN'), ('in', 'IN'), ('2015', 'CD'), ('that', 'WDT'), ('gave', 'VBD'), ('Google', 'NNP'), ('access', 'NN'), ('to', 'TO'), ('Twitter', 'NNP'), (\"'s\", 'POS'), ('firehose', 'NN'), ('.', '.')]\n",
      "[('Google', 'DET'), ('and', 'CONJ'), ('Twitter', 'DET'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'DET'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'DET'), (\"'s\", 'VERB'), ('firehose', 'DET'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(word_tokenize(lines[2])))\n",
    "print(Viterbi(word_tokenize(lines[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Google', 'DET'), ('and', 'CONJ')]]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents=Viterbi(word_tokenize(lines[2]))\n",
    "[train_sents[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "brown_sents = brown.sents(categories='news')\n",
    "train_sents = brown_tagged_sents[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('Grand', 'JJ-TL'),\n",
       "  ('Jury', 'NN-TL'),\n",
       "  ('said', 'VBD'),\n",
       "  ('Friday', 'NR'),\n",
       "  ('an', 'AT'),\n",
       "  ('investigation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Atlanta's\", 'NP$'),\n",
       "  ('recent', 'JJ'),\n",
       "  ('primary', 'NN'),\n",
       "  ('election', 'NN'),\n",
       "  ('produced', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('no', 'AT'),\n",
       "  ('evidence', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('that', 'CS'),\n",
       "  ('any', 'DTI'),\n",
       "  ('irregularities', 'NNS'),\n",
       "  ('took', 'VBD'),\n",
       "  ('place', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('further', 'RBR'),\n",
       "  ('said', 'VBD'),\n",
       "  ('in', 'IN'),\n",
       "  ('term-end', 'NN'),\n",
       "  ('presentments', 'NNS'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('Executive', 'JJ-TL'),\n",
       "  ('Committee', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('which', 'WDT'),\n",
       "  ('had', 'HVD'),\n",
       "  ('over-all', 'JJ'),\n",
       "  ('charge', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('deserves', 'VBZ'),\n",
       "  ('the', 'AT'),\n",
       "  ('praise', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('thanks', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('of', 'IN-TL'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('manner', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('conducted', 'VBN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('September-October', 'NP'),\n",
       "  ('term', 'NN'),\n",
       "  ('jury', 'NN'),\n",
       "  ('had', 'HVD'),\n",
       "  ('been', 'BEN'),\n",
       "  ('charged', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('Superior', 'JJ-TL'),\n",
       "  ('Court', 'NN-TL'),\n",
       "  ('Judge', 'NN-TL'),\n",
       "  ('Durwood', 'NP'),\n",
       "  ('Pye', 'NP'),\n",
       "  ('to', 'TO'),\n",
       "  ('investigate', 'VB'),\n",
       "  ('reports', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('possible', 'JJ'),\n",
       "  ('``', '``'),\n",
       "  ('irregularities', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('hard-fought', 'JJ'),\n",
       "  ('primary', 'NN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('won', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('Mayor-nominate', 'NN-TL'),\n",
       "  ('Ivan', 'NP'),\n",
       "  ('Allen', 'NP'),\n",
       "  ('Jr.', 'NP'),\n",
       "  ('.', '.')],\n",
       " [('``', '``'),\n",
       "  ('Only', 'RB'),\n",
       "  ('a', 'AT'),\n",
       "  ('relative', 'JJ'),\n",
       "  ('handful', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('such', 'JJ'),\n",
       "  ('reports', 'NNS'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('received', 'VBN'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('considering', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('widespread', 'JJ'),\n",
       "  ('interest', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('number', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('voters', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'AT'),\n",
       "  ('size', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('city', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('it', 'PPS'),\n",
       "  ('did', 'DOD'),\n",
       "  ('find', 'VB'),\n",
       "  ('that', 'CS'),\n",
       "  ('many', 'AP'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Georgia's\", 'NP$'),\n",
       "  ('registration', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('election', 'NN'),\n",
       "  ('laws', 'NNS'),\n",
       "  ('``', '``'),\n",
       "  ('are', 'BER'),\n",
       "  ('outmoded', 'JJ'),\n",
       "  ('or', 'CC'),\n",
       "  ('inadequate', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('often', 'RB'),\n",
       "  ('ambiguous', 'JJ'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('It', 'PPS'),\n",
       "  ('recommended', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('Fulton', 'NP'),\n",
       "  ('legislators', 'NNS'),\n",
       "  ('act', 'VB'),\n",
       "  ('``', '``'),\n",
       "  ('to', 'TO'),\n",
       "  ('have', 'HV'),\n",
       "  ('these', 'DTS'),\n",
       "  ('laws', 'NNS'),\n",
       "  ('studied', 'VBN'),\n",
       "  ('and', 'CC'),\n",
       "  ('revised', 'VBN'),\n",
       "  ('to', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('end', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('modernizing', 'VBG'),\n",
       "  ('and', 'CC'),\n",
       "  ('improving', 'VBG'),\n",
       "  ('them', 'PPO'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('grand', 'JJ'),\n",
       "  ('jury', 'NN'),\n",
       "  ('commented', 'VBD'),\n",
       "  ('on', 'IN'),\n",
       "  ('a', 'AT'),\n",
       "  ('number', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('other', 'AP'),\n",
       "  ('topics', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('among', 'IN'),\n",
       "  ('them', 'PPO'),\n",
       "  ('the', 'AT'),\n",
       "  ('Atlanta', 'NP'),\n",
       "  ('and', 'CC'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('purchasing', 'VBG'),\n",
       "  ('departments', 'NNS'),\n",
       "  ('which', 'WDT'),\n",
       "  ('it', 'PPS'),\n",
       "  ('said', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('are', 'BER'),\n",
       "  ('well', 'QL'),\n",
       "  ('operated', 'VBN'),\n",
       "  ('and', 'CC'),\n",
       "  ('follow', 'VB'),\n",
       "  ('generally', 'RB'),\n",
       "  ('accepted', 'VBN'),\n",
       "  ('practices', 'NNS'),\n",
       "  ('which', 'WDT'),\n",
       "  ('inure', 'VB'),\n",
       "  ('to', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('best', 'JJT'),\n",
       "  ('interest', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('both', 'ABX'),\n",
       "  ('governments', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('Merger', 'NN-HL'), ('proposed', 'VBN-HL')],\n",
       " [('However', 'WRB'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('it', 'PPS'),\n",
       "  ('believes', 'VBZ'),\n",
       "  ('``', '``'),\n",
       "  ('these', 'DTS'),\n",
       "  ('two', 'CD'),\n",
       "  ('offices', 'NNS'),\n",
       "  ('should', 'MD'),\n",
       "  ('be', 'BE'),\n",
       "  ('combined', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('achieve', 'VB'),\n",
       "  ('greater', 'JJR'),\n",
       "  ('efficiency', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('reduce', 'VB'),\n",
       "  ('the', 'AT'),\n",
       "  ('cost', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('administration', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('Purchasing', 'VBG-TL'),\n",
       "  ('Department', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('is', 'BEZ'),\n",
       "  ('lacking', 'VBG'),\n",
       "  ('in', 'IN'),\n",
       "  ('experienced', 'VBN'),\n",
       "  ('clerical', 'JJ'),\n",
       "  ('personnel', 'NNS'),\n",
       "  ('as', 'CS'),\n",
       "  ('a', 'AT'),\n",
       "  ('result', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('city', 'NN'),\n",
       "  ('personnel', 'NNS'),\n",
       "  ('policies', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('It', 'PPS'),\n",
       "  ('urged', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('city', 'NN'),\n",
       "  ('``', '``'),\n",
       "  ('take', 'VB'),\n",
       "  ('steps', 'NNS'),\n",
       "  ('to', 'TO'),\n",
       "  ('remedy', 'VB'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('this', 'DT'),\n",
       "  ('problem', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Implementation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Georgia's\", 'NP$'),\n",
       "  ('automobile', 'NN'),\n",
       "  ('title', 'NN'),\n",
       "  ('law', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('also', 'RB'),\n",
       "  ('recommended', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('outgoing', 'JJ'),\n",
       "  ('jury', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('It', 'PPS'),\n",
       "  ('urged', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('next', 'AP'),\n",
       "  ('Legislature', 'NN-TL'),\n",
       "  ('``', '``'),\n",
       "  ('provide', 'VB'),\n",
       "  ('enabling', 'VBG'),\n",
       "  ('funds', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('re-set', 'VB'),\n",
       "  ('the', 'AT'),\n",
       "  ('effective', 'JJ'),\n",
       "  ('date', 'NN'),\n",
       "  ('so', 'CS'),\n",
       "  ('that', 'CS'),\n",
       "  ('an', 'AT'),\n",
       "  ('orderly', 'JJ'),\n",
       "  ('implementation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('law', 'NN'),\n",
       "  ('may', 'MD'),\n",
       "  ('be', 'BE'),\n",
       "  ('effected', 'VBN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('grand', 'JJ'),\n",
       "  ('jury', 'NN'),\n",
       "  ('took', 'VBD'),\n",
       "  ('a', 'AT'),\n",
       "  ('swipe', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('State', 'NN-TL'),\n",
       "  ('Welfare', 'NN-TL'),\n",
       "  (\"Department's\", 'NN$-TL'),\n",
       "  ('handling', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('federal', 'JJ'),\n",
       "  ('funds', 'NNS'),\n",
       "  ('granted', 'VBN'),\n",
       "  ('for', 'IN'),\n",
       "  ('child', 'NN'),\n",
       "  ('welfare', 'NN'),\n",
       "  ('services', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('foster', 'JJ'),\n",
       "  ('homes', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [('``', '``'),\n",
       "  ('This', 'DT'),\n",
       "  ('is', 'BEZ'),\n",
       "  ('one', 'CD'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('major', 'JJ'),\n",
       "  ('items', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('general', 'JJ'),\n",
       "  ('assistance', 'NN'),\n",
       "  ('program', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  (',', ','),\n",
       "  ('but', 'CC'),\n",
       "  ('the', 'AT'),\n",
       "  ('State', 'NN-TL'),\n",
       "  ('Welfare', 'NN-TL'),\n",
       "  ('Department', 'NN-TL'),\n",
       "  ('``', '``'),\n",
       "  ('has', 'HVZ'),\n",
       "  ('seen', 'VBN'),\n",
       "  ('fit', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('distribute', 'VB'),\n",
       "  ('these', 'DTS'),\n",
       "  ('funds', 'NNS'),\n",
       "  ('through', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('welfare', 'NN'),\n",
       "  ('departments', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('all', 'ABN'),\n",
       "  ('the', 'AT'),\n",
       "  ('counties', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('state', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('exception', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('which', 'WDT'),\n",
       "  ('receives', 'VBZ'),\n",
       "  ('none', 'PN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('money', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jurors', 'NNS'),\n",
       "  ('said', 'VBD'),\n",
       "  ('they', 'PPSS'),\n",
       "  ('realize', 'VB'),\n",
       "  ('``', '``'),\n",
       "  ('a', 'AT'),\n",
       "  ('proportionate', 'JJ'),\n",
       "  ('distribution', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('these', 'DTS'),\n",
       "  ('funds', 'NNS'),\n",
       "  ('might', 'MD'),\n",
       "  ('disable', 'VB'),\n",
       "  ('this', 'DT'),\n",
       "  ('program', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('our', 'PP$'),\n",
       "  ('less', 'QL'),\n",
       "  ('populous', 'JJ'),\n",
       "  ('counties', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('Nevertheless', 'RB'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('we', 'PPSS'),\n",
       "  ('feel', 'VB'),\n",
       "  ('that', 'CS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('future', 'NN'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('should', 'MD'),\n",
       "  ('receive', 'VB'),\n",
       "  ('some', 'DTI'),\n",
       "  ('portion', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('these', 'DTS'),\n",
       "  ('available', 'JJ'),\n",
       "  ('funds', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jurors', 'NNS'),\n",
       "  ('said', 'VBD'),\n",
       "  ('.', '.')],\n",
       " [('``', '``'),\n",
       "  ('Failure', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('do', 'DO'),\n",
       "  ('this', 'DT'),\n",
       "  ('will', 'MD'),\n",
       "  ('continue', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('place', 'VB'),\n",
       "  ('a', 'AT'),\n",
       "  ('disproportionate', 'JJ'),\n",
       "  ('burden', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('on', 'IN'),\n",
       "  ('Fulton', 'NP'),\n",
       "  ('taxpayers', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('also', 'RB'),\n",
       "  ('commented', 'VBD'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('Fulton', 'NP'),\n",
       "  (\"ordinary's\", 'NN$'),\n",
       "  ('court', 'NN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('has', 'HVZ'),\n",
       "  ('been', 'BEN'),\n",
       "  ('under', 'IN'),\n",
       "  ('fire', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('its', 'PP$'),\n",
       "  ('practices', 'NNS'),\n",
       "  ('in', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('appointment', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('appraisers', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('guardians', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('administrators', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'AT'),\n",
       "  ('awarding', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('fees', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('compensation', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Wards', 'NNS-HL'), ('protected', 'VBN-HL')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('it', 'PPS'),\n",
       "  ('found', 'VBD'),\n",
       "  ('the', 'AT'),\n",
       "  ('court', 'NN'),\n",
       "  ('``', '``'),\n",
       "  ('has', 'HVZ'),\n",
       "  ('incorporated', 'VBN'),\n",
       "  ('into', 'IN'),\n",
       "  ('its', 'PP$'),\n",
       "  ('operating', 'VBG'),\n",
       "  ('procedures', 'NNS'),\n",
       "  ('the', 'AT'),\n",
       "  ('recommendations', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('of', 'IN'),\n",
       "  ('two', 'CD'),\n",
       "  ('previous', 'JJ'),\n",
       "  ('grand', 'JJ'),\n",
       "  ('juries', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  ('Bar', 'NN-TL'),\n",
       "  ('Association', 'NN-TL'),\n",
       "  ('and', 'CC'),\n",
       "  ('an', 'AT'),\n",
       "  ('interim', 'NN'),\n",
       "  ('citizens', 'NNS'),\n",
       "  ('committee', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('``', '``'),\n",
       "  ('These', 'DTS'),\n",
       "  ('actions', 'NNS'),\n",
       "  ('should', 'MD'),\n",
       "  ('serve', 'VB'),\n",
       "  ('to', 'TO'),\n",
       "  ('protect', 'VB'),\n",
       "  ('in', 'IN'),\n",
       "  ('fact', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('in', 'IN'),\n",
       "  ('effect', 'NN'),\n",
       "  ('the', 'AT'),\n",
       "  (\"court's\", 'NN$'),\n",
       "  ('wards', 'NNS'),\n",
       "  ('from', 'IN'),\n",
       "  ('undue', 'JJ'),\n",
       "  ('costs', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('its', 'PP$'),\n",
       "  ('appointed', 'VBN'),\n",
       "  ('and', 'CC'),\n",
       "  ('elected', 'VBN'),\n",
       "  ('servants', 'NNS'),\n",
       "  ('from', 'IN'),\n",
       "  ('unmeritorious', 'JJ'),\n",
       "  ('criticisms', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('.', '.')],\n",
       " [('Regarding', 'IN'),\n",
       "  (\"Atlanta's\", 'NP$'),\n",
       "  ('new', 'JJ'),\n",
       "  ('multi-million-dollar', 'JJ'),\n",
       "  ('airport', 'NN'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('recommended', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('that', 'CS'),\n",
       "  ('when', 'WRB'),\n",
       "  ('the', 'AT'),\n",
       "  ('new', 'JJ'),\n",
       "  ('management', 'NN'),\n",
       "  ('takes', 'VBZ'),\n",
       "  ('charge', 'NN'),\n",
       "  ('Jan.', 'NP'),\n",
       "  ('1', 'CD'),\n",
       "  ('the', 'AT'),\n",
       "  ('airport', 'NN'),\n",
       "  ('be', 'BE'),\n",
       "  ('operated', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('a', 'AT'),\n",
       "  ('manner', 'NN'),\n",
       "  ('that', 'WPS'),\n",
       "  ('will', 'MD'),\n",
       "  ('eliminate', 'VB'),\n",
       "  ('political', 'JJ'),\n",
       "  ('influences', 'NNS'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('did', 'DOD'),\n",
       "  ('not', '*'),\n",
       "  ('elaborate', 'VB'),\n",
       "  (',', ','),\n",
       "  ('but', 'CC'),\n",
       "  ('it', 'PPS'),\n",
       "  ('added', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('``', '``'),\n",
       "  ('there', 'EX'),\n",
       "  ('should', 'MD'),\n",
       "  ('be', 'BE'),\n",
       "  ('periodic', 'JJ'),\n",
       "  ('surveillance', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('pricing', 'VBG'),\n",
       "  ('practices', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('concessionaires', 'NNS'),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('purpose', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('keeping', 'VBG'),\n",
       "  ('the', 'AT'),\n",
       "  ('prices', 'NNS'),\n",
       "  ('reasonable', 'JJ'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('Ask', 'VB-HL'), ('jail', 'NN-HL'), ('deputies', 'NNS-HL')],\n",
       " [('On', 'IN'),\n",
       "  ('other', 'AP'),\n",
       "  ('matters', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('recommended', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  (':', ':'),\n",
       "  ('(', '('),\n",
       "  ('1', 'CD'),\n",
       "  (')', ')')],\n",
       " [('Four', 'CD'),\n",
       "  ('additional', 'JJ'),\n",
       "  ('deputies', 'NNS'),\n",
       "  ('be', 'BE'),\n",
       "  ('employed', 'VBN'),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('Jail', 'NN-TL'),\n",
       "  ('and', 'CC'),\n",
       "  ('``', '``'),\n",
       "  ('a', 'AT'),\n",
       "  ('doctor', 'NN'),\n",
       "  (',', ','),\n",
       "  ('medical', 'JJ'),\n",
       "  ('intern', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('extern', 'NN'),\n",
       "  ('be', 'BE'),\n",
       "  ('employed', 'VBN'),\n",
       "  ('for', 'IN'),\n",
       "  ('night', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('weekend', 'NN'),\n",
       "  ('duty', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('jail', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('.', '.')],\n",
       " [('(', '('), ('2', 'CD'), (')', ')')],\n",
       " [('Fulton', 'NP'),\n",
       "  ('legislators', 'NNS'),\n",
       "  ('``', '``'),\n",
       "  ('work', 'VB'),\n",
       "  ('with', 'IN'),\n",
       "  ('city', 'NN'),\n",
       "  ('officials', 'NNS'),\n",
       "  ('to', 'TO'),\n",
       "  ('pass', 'VB'),\n",
       "  ('enabling', 'VBG'),\n",
       "  ('legislation', 'NN'),\n",
       "  ('that', 'WPS'),\n",
       "  ('will', 'MD'),\n",
       "  ('permit', 'VB'),\n",
       "  ('the', 'AT'),\n",
       "  ('establishment', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('a', 'AT'),\n",
       "  ('fair', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('equitable', 'JJ'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('pension', 'NN'),\n",
       "  ('plan', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('city', 'NN'),\n",
       "  ('employes', 'NNS'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('praised', 'VBD'),\n",
       "  ('the', 'AT'),\n",
       "  ('administration', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('operation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  ('Police', 'NNS-TL'),\n",
       "  ('Department', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('Tax', 'NN-TL'),\n",
       "  (\"Commissioner's\", 'NN$-TL'),\n",
       "  ('Office', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('the', 'AT'),\n",
       "  ('Bellwood', 'NP'),\n",
       "  ('and', 'CC'),\n",
       "  ('Alpharetta', 'NP'),\n",
       "  ('prison', 'NN'),\n",
       "  ('farms', 'NNS'),\n",
       "  (',', ','),\n",
       "  ('Grady', 'NP-TL'),\n",
       "  ('Hospital', 'NN-TL'),\n",
       "  ('and', 'CC'),\n",
       "  ('the', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('Health', 'NN-TL'),\n",
       "  ('Department', 'NN-TL'),\n",
       "  ('.', '.')],\n",
       " [('Mayor', 'NN-TL'),\n",
       "  ('William', 'NP'),\n",
       "  ('B.', 'NP'),\n",
       "  ('Hartsfield', 'NP'),\n",
       "  ('filed', 'VBD'),\n",
       "  ('suit', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('divorce', 'NN'),\n",
       "  ('from', 'IN'),\n",
       "  ('his', 'PP$'),\n",
       "  ('wife', 'NN'),\n",
       "  (',', ','),\n",
       "  ('Pearl', 'NP'),\n",
       "  ('Williams', 'NP'),\n",
       "  ('Hartsfield', 'NP'),\n",
       "  (',', ','),\n",
       "  ('in', 'IN'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('Superior', 'JJ-TL'),\n",
       "  ('Court', 'NN-TL'),\n",
       "  ('Friday', 'NR'),\n",
       "  ('.', '.')],\n",
       " [('His', 'PP$'),\n",
       "  ('petition', 'NN'),\n",
       "  ('charged', 'VBD'),\n",
       "  ('mental', 'JJ'),\n",
       "  ('cruelty', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('couple', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('married', 'VBN'),\n",
       "  ('Aug.', 'NP'),\n",
       "  ('2', 'CD'),\n",
       "  (',', ','),\n",
       "  ('1913', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('They', 'PPSS'),\n",
       "  ('have', 'HV'),\n",
       "  ('a', 'AT'),\n",
       "  ('son', 'NN'),\n",
       "  (',', ','),\n",
       "  ('William', 'NP'),\n",
       "  ('Berry', 'NP'),\n",
       "  ('Jr.', 'NP'),\n",
       "  (',', ','),\n",
       "  ('and', 'CC'),\n",
       "  ('a', 'AT'),\n",
       "  ('daughter', 'NN'),\n",
       "  (',', ','),\n",
       "  ('Mrs.', 'NP'),\n",
       "  ('J.', 'NP'),\n",
       "  ('M.', 'NP'),\n",
       "  ('Cheshire', 'NP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Griffin', 'NP'),\n",
       "  ('.', '.')],\n",
       " [('Attorneys', 'NNS'),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('mayor', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('an', 'AT'),\n",
       "  ('amicable', 'JJ'),\n",
       "  ('property', 'NN'),\n",
       "  ('settlement', 'NN'),\n",
       "  ('has', 'HVZ'),\n",
       "  ('been', 'BEN'),\n",
       "  ('agreed', 'VBN'),\n",
       "  ('upon', 'RB'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('petition', 'NN'),\n",
       "  ('listed', 'VBD'),\n",
       "  ('the', 'AT'),\n",
       "  (\"mayor's\", 'NN$'),\n",
       "  ('occupation', 'NN'),\n",
       "  ('as', 'CS'),\n",
       "  ('``', '``'),\n",
       "  ('attorney', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('and', 'CC'),\n",
       "  ('his', 'PP$'),\n",
       "  ('age', 'NN'),\n",
       "  ('as', 'CS'),\n",
       "  ('71', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('It', 'PPS'),\n",
       "  ('listed', 'VBD'),\n",
       "  ('his', 'PP$'),\n",
       "  (\"wife's\", 'NN$'),\n",
       "  ('age', 'NN'),\n",
       "  ('as', 'CS'),\n",
       "  ('74', 'CD'),\n",
       "  ('and', 'CC'),\n",
       "  ('place', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('birth', 'NN'),\n",
       "  ('as', 'CS'),\n",
       "  ('Opelika', 'NP'),\n",
       "  (',', ','),\n",
       "  ('Ala.', 'NP'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('petition', 'NN'),\n",
       "  ('said', 'VBD'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('couple', 'NN'),\n",
       "  ('has', 'HVZ'),\n",
       "  ('not', '*'),\n",
       "  ('lived', 'VBN'),\n",
       "  ('together', 'RB'),\n",
       "  ('as', 'CS'),\n",
       "  ('man', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('wife', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('more', 'AP'),\n",
       "  ('than', 'IN'),\n",
       "  ('a', 'AT'),\n",
       "  ('year', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('Hartsfield', 'NP'),\n",
       "  ('home', 'NR'),\n",
       "  ('is', 'BEZ'),\n",
       "  ('at', 'IN'),\n",
       "  ('637', 'CD'),\n",
       "  ('E.', 'NP'),\n",
       "  ('Pelham', 'NP'),\n",
       "  ('Rd.', 'NN-TL'),\n",
       "  ('Aj', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Henry', 'NP'),\n",
       "  ('L.', 'NP'),\n",
       "  ('Bowden', 'NP'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('listed', 'VBN'),\n",
       "  ('on', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('petition', 'NN'),\n",
       "  ('as', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  (\"mayor's\", 'NN$'),\n",
       "  ('attorney', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 'NN')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger([train_sents[0:2]], backoff=t0)\n",
    "t2 = nltk.BigramTagger([train_sents[0:2]], backoff=t1)\n",
    "t2.tag([\"India\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt2=nltk.BigramTagger([tagged_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Domaine', None)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt2.tag(['Domaine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Temple', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('however', 'ADV'),\n",
       " (',', '.'),\n",
       " ('harshly', 'ADV'),\n",
       " ('criticized', 'VERB'),\n",
       " ('Sea', 'NOUN'),\n",
       " ('Containers', 'NOUN'),\n",
       " (\"'\", 'PRT'),\n",
       " ('plan', 'NOUN'),\n",
       " ('yesterday', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('*-1', 'X'),\n",
       " ('characterizing', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('``', '.'),\n",
       " ('highly', 'ADV'),\n",
       " ('conditional', 'ADJ'),\n",
       " ('device', 'NOUN'),\n",
       " ('designed', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('*-2', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('entrench', 'VERB'),\n",
       " ('management', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('confuse', 'VERB'),\n",
       " ('shareholders', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('prevent', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " ('from', 'ADP'),\n",
       " ('*-3', 'X'),\n",
       " ('accepting', 'VERB'),\n",
       " ('our', 'PRON'),\n",
       " ('superior', 'ADJ'),\n",
       " ('cash', 'NOUN'),\n",
       " ('offer', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('It', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('later', 'ADJ'),\n",
       " ('applied', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('other', 'ADJ'),\n",
       " ('new-car', 'NOUN'),\n",
       " ('programs', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('including', 'VERB'),\n",
       " ('those', 'DET'),\n",
       " ('that', 'DET'),\n",
       " ('*T*-1', 'X'),\n",
       " ('produced', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('Ford', 'NOUN'),\n",
       " ('Thunderbird', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Mercury', 'NOUN'),\n",
       " ('Cougar', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('In', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('past', 'ADJ'),\n",
       " ('five', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Japanese', 'ADJ'),\n",
       " ('companies', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('tripled', 'VERB'),\n",
       " ('their', 'PRON'),\n",
       " ('commitments', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Asia', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('$', '.'),\n",
       " ('5.57', 'NUM'),\n",
       " ('billion', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('His', 'PRON'),\n",
       " ('duties', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('chief', 'ADJ'),\n",
       " ('executive', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('assumed', 'VERB'),\n",
       " ('*-121', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('Chairman', 'NOUN'),\n",
       " ('Jay', 'NOUN'),\n",
       " ('B.', 'NOUN'),\n",
       " ('Langner', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Also', 'ADV'),\n",
       " (',', '.'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Vargas', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('barred', 'VERB'),\n",
       " ('*-152', 'X'),\n",
       " ('from', 'ADP'),\n",
       " ('association', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('any', 'DET'),\n",
       " ('NASD', 'NOUN'),\n",
       " ('member', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('FTC', 'NOUN'),\n",
       " ('budget', 'NOUN'),\n",
       " ('request', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('70', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " (',', '.'),\n",
       " ('about', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('34', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('of', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('*T*-1', 'X'),\n",
       " ('would', 'VERB'),\n",
       " ('go', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('antitrust', 'ADJ'),\n",
       " ('enforcement', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('would', 'VERB'),\n",
       " ('also', 'ADV'),\n",
       " ('be', 'VERB'),\n",
       " ('cut', 'VERB'),\n",
       " ('*-85', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('15', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Senate', 'NOUN'),\n",
       " ('plans', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('take', 'VERB'),\n",
       " ('up', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('measure', 'NOUN'),\n",
       " ('quickly', 'ADV'),\n",
       " ('and', 'CONJ'),\n",
       " ('is', 'VERB'),\n",
       " ('expected', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('pass', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('average', 'ADJ'),\n",
       " ('number', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('FT-SE', 'NOUN'),\n",
       " ('option', 'NOUN'),\n",
       " ('contracts', 'NOUN'),\n",
       " ('traded', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('on', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('London', 'NOUN'),\n",
       " ('exchange', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('surged', 'VERB'),\n",
       " ('nearly', 'ADV'),\n",
       " ('tenfold', 'ADV'),\n",
       " ('since', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('contract', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('launch', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('1984', 'NUM'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('We', 'PRON'),\n",
       " ('had', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('do', 'VERB'),\n",
       " ('something', 'NOUN'),\n",
       " ('structurally', 'ADV'),\n",
       " ('and', 'CONJ'),\n",
       " ('radically', 'ADV'),\n",
       " ('different', 'ADJ'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('They', 'PRON'),\n",
       " ('call', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('``', '.'),\n",
       " ('photographic', 'ADJ'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('October', 'NOUN'),\n",
       " ('survey', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('corporate', 'ADJ'),\n",
       " ('purchasing', 'VERB'),\n",
       " ('managers', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('as', 'ADP'),\n",
       " ('*', 'X'),\n",
       " ('expected', 'VERB'),\n",
       " (',', '.'),\n",
       " ('provided', 'VERB'),\n",
       " ('evidence', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('economic', 'ADJ'),\n",
       " ('growth', 'NOUN'),\n",
       " ('remains', 'VERB'),\n",
       " ('subdued', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('We', 'PRON'),\n",
       " ('need', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('clarify', 'VERB'),\n",
       " ('what', 'PRON'),\n",
       " ('exactly', 'ADV'),\n",
       " ('*T*-188', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('wrong', 'ADJ'),\n",
       " ('with', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('``', '.'),\n",
       " ('Professional', 'ADJ'),\n",
       " ('sugar', 'NOUN'),\n",
       " ('people', 'NOUN'),\n",
       " ('here', 'ADV'),\n",
       " ('who', 'PRON'),\n",
       " ('*T*-1', 'X'),\n",
       " ('have', 'VERB'),\n",
       " ('strong', 'ADJ'),\n",
       " ('contacts', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Brazilian', 'ADJ'),\n",
       " ('sugar', 'NOUN'),\n",
       " ('industry', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('unable', 'ADJ'),\n",
       " ('*-3', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('confirm', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('reports', 'NOUN'),\n",
       " ('or', 'CONJ'),\n",
       " ('get', 'VERB'),\n",
       " ('enough', 'ADJ'),\n",
       " ('information', 'NOUN'),\n",
       " ('0', 'X'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('clarify', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('situation', 'NOUN'),\n",
       " ('*T*-4', 'X'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('he', 'PRON'),\n",
       " ('said', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('.', '.'),\n",
       " ('Diamond', 'NOUN'),\n",
       " ('Creek', 'NOUN'),\n",
       " ('1985', 'NUM'),\n",
       " ('Lake', 'NOUN'),\n",
       " ('Vineyard', 'NOUN'),\n",
       " ('Cabernet', 'NOUN'),\n",
       " ('weighed', 'VERB'),\n",
       " ('in', 'PRT'),\n",
       " ('this', 'DET'),\n",
       " ('fall', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('sticker', 'NOUN'),\n",
       " ('price', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('100', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('bottle', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Primerica', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('as', 'ADP'),\n",
       " ('*', 'X'),\n",
       " ('expected', 'VERB'),\n",
       " (',', '.'),\n",
       " ('also', 'ADV'),\n",
       " ('acquired', 'VERB'),\n",
       " ('certain', 'ADJ'),\n",
       " ('assets', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('agency', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('assumed', 'VERB'),\n",
       " ('certain', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('its', 'PRON'),\n",
       " ('liabilities', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRON'),\n",
       " ('also', 'ADV'),\n",
       " ('claims', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('the', 'DET'),\n",
       " ('carrier', 'NOUN'),\n",
       " ('costs', 'VERB'),\n",
       " ('less', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('takes', 'VERB'),\n",
       " ('up', 'PRT'),\n",
       " ('less', 'ADJ'),\n",
       " ('space', 'NOUN'),\n",
       " ('than', 'ADP'),\n",
       " ('most', 'ADJ'),\n",
       " ('paper', 'NOUN'),\n",
       " ('carriers', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Last', 'ADJ'),\n",
       " ('week', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Miami-based', 'ADJ'),\n",
       " ('Carnival', 'NOUN'),\n",
       " ('disclosed', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Waertsilae', 'NOUN'),\n",
       " ('Marine', 'NOUN'),\n",
       " ('Industries', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('Finnish', 'ADJ'),\n",
       " ('shipyard', 'NOUN'),\n",
       " ('that', 'DET'),\n",
       " ('*T*-1', 'X'),\n",
       " ('is', 'VERB'),\n",
       " ('building', 'VERB'),\n",
       " ('Carnival', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('new', 'ADJ'),\n",
       " ('cruise', 'NOUN'),\n",
       " ('ships', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('planned', 'VERB'),\n",
       " ('*-2', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('file', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('bankruptcy', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('ASLACTON', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('England', 'NOUN'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Reupke', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('52', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('27-year', 'ADJ'),\n",
       " ('Reuters', 'NOUN'),\n",
       " ('veteran', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('had', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('information-services', 'NOUN'),\n",
       " ('company', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('general', 'ADJ'),\n",
       " ('manager', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('only', 'ADV'),\n",
       " ('six', 'NUM'),\n",
       " ('months', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Previously', 'ADV'),\n",
       " (',', '.'),\n",
       " ('watch', 'NOUN'),\n",
       " ('imports', 'NOUN'),\n",
       " ('were', 'VERB'),\n",
       " ('denied', 'VERB'),\n",
       " ('*-37', 'X'),\n",
       " ('such', 'ADJ'),\n",
       " ('duty-free', 'ADJ'),\n",
       " ('treatment', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('Fed', 'NOUN'),\n",
       " ('cut', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('key', 'ADJ'),\n",
       " ('federal', 'ADJ'),\n",
       " ('funds', 'NOUN'),\n",
       " ('interest', 'NOUN'),\n",
       " ('rate', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('about', 'ADV'),\n",
       " ('0.25', 'NUM'),\n",
       " ('percentage', 'NOUN'),\n",
       " ('point', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('8.75', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('after', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Oct.', 'NOUN'),\n",
       " ('13', 'NUM'),\n",
       " ('stock', 'NOUN'),\n",
       " ('market', 'NOUN'),\n",
       " ('plunge', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('but', 'CONJ'),\n",
       " ('has', 'VERB'),\n",
       " ('shown', 'VERB'),\n",
       " ('no', 'DET'),\n",
       " ('sign', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('movement', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('.', '.'),\n",
       " ('Moreover', 'ADV'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('framers', 'NOUN'),\n",
       " ('believed', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('nation', 'NOUN'),\n",
       " ('needed', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('unitary', 'ADJ'),\n",
       " ('executive', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('independence', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('resources', 'NOUN'),\n",
       " ('0', 'X'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('perform', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('executive', 'NOUN'),\n",
       " ('functions', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Confederation', 'NOUN'),\n",
       " ('Congress', 'NOUN'),\n",
       " ('had', 'VERB'),\n",
       " ('performed', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('poorly', 'ADV'),\n",
       " ('under', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('Articles', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Confederation', 'NOUN'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('For', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " ('ended', 'VERB'),\n",
       " ('Sept.', 'NOUN'),\n",
       " ('30', 'NUM'),\n",
       " (',', '.'),\n",
       " ('Ralston', 'NOUN'),\n",
       " ('earned', 'VERB'),\n",
       " ('$', '.'),\n",
       " ('422.5', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " (',', '.'),\n",
       " ('or', 'CONJ'),\n",
       " ('$', '.'),\n",
       " ('6.44', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('up', 'ADV'),\n",
       " ('8.9', 'NUM'),\n",
       " ('%', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('387.8', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " (',', '.'),\n",
       " ('or', 'CONJ'),\n",
       " ('$', '.'),\n",
       " ('5.63', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('*EXP*-1', 'X'),\n",
       " ('is', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('clear', 'ADJ'),\n",
       " (',', '.'),\n",
       " ('however', 'ADV'),\n",
       " (',', '.'),\n",
       " ('whether', 'ADP'),\n",
       " ('support', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('proposal', 'NOUN'),\n",
       " ('will', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('broad', 'ADJ'),\n",
       " ('enough', 'ADV'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('pose', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('serious', 'ADJ'),\n",
       " ('challenge', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('the', 'DET'),\n",
       " ('White', 'NOUN'),\n",
       " ('House', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('acid-rain', 'NOUN'),\n",
       " ('plan', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Your', 'PRON'),\n",
       " ('Oct.', 'NOUN'),\n",
       " ('6', 'NUM'),\n",
       " ('article', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('Japan', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('Financial', 'ADJ'),\n",
       " ('Firms', 'NOUN'),\n",
       " ('Lure', 'VERB'),\n",
       " ('Science', 'NOUN'),\n",
       " ('Graduates', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " ('states', 'VERB'),\n",
       " (',', '.'),\n",
       " ('``', '.'),\n",
       " ('Industrial', 'ADJ'),\n",
       " ('companies', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('accusing', 'VERB'),\n",
       " ('financial', 'ADJ'),\n",
       " ('institutions', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('*-1', 'X'),\n",
       " ('jeopardizing', 'VERB'),\n",
       " ('Japan', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('economy', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('*-2', 'X'),\n",
       " ('raising', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('salary', 'NOUN'),\n",
       " ('stakes', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('new', 'ADJ'),\n",
       " ('employees', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('Imports', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('types', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('watches', 'NOUN'),\n",
       " ('that', 'DET'),\n",
       " ('*T*-36', 'X'),\n",
       " ('now', 'ADV'),\n",
       " ('will', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('eligible', 'ADJ'),\n",
       " ('for', 'ADP'),\n",
       " ('duty-free', 'ADJ'),\n",
       " ('treatment', 'NOUN'),\n",
       " ('totaled', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " ('$', '.'),\n",
       " ('37.3', 'NUM'),\n",
       " ('million', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('*ICH*-1', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('1988', 'NUM'),\n",
       " (',', '.'),\n",
       " ('a', 'DET'),\n",
       " ('relatively', 'ADV'),\n",
       " ('small', 'ADJ'),\n",
       " ('share', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('$', '.'),\n",
       " ('1.5', 'NUM'),\n",
       " ('billion', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('in', 'ADP'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('watch', 'NOUN'),\n",
       " ('imports', 'NOUN'),\n",
       " ('that', 'DET'),\n",
       " ('year', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('according', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('an', 'DET'),\n",
       " ('aide', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('Trade', 'NOUN'),\n",
       " ('Representative', 'NOUN'),\n",
       " ('Carla', 'NOUN'),\n",
       " ('Hills', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DET'),\n",
       " ('total', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('18', 'NUM'),\n",
       " ('deaths', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('malignant', 'ADJ'),\n",
       " ('mesothelioma', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('lung', 'NOUN'),\n",
       " ('cancer', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('asbestosis', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('far', 'ADV'),\n",
       " ('higher', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('*', 'X'),\n",
       " ('expected', 'VERB'),\n",
       " ('*?*', 'X'),\n",
       " (',', '.'),\n",
       " ('the', 'DET'),\n",
       " ('researchers', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('Wall', 'NOUN'),\n",
       " ('Street', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('facing', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('Catch-22', 'NOUN'),\n",
       " ('situation', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('says', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('Mr.', 'NOUN'),\n",
       " ('Mahoney', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Moody', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('.', '.'),\n",
       " ('Jaguar', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('a', 'DET'),\n",
       " ('U.K.', 'NOUN'),\n",
       " ('luxury', 'NOUN'),\n",
       " ('auto', 'NOUN'),\n",
       " ('maker', 'NOUN'),\n",
       " ('being', 'VERB'),\n",
       " ('pursued', 'VERB'),\n",
       " ('*', 'X'),\n",
       " ('by', 'ADP'),\n",
       " ('Ford', 'NOUN'),\n",
       " ('Motor', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('General', 'NOUN'),\n",
       " ('Motors', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('gained', 'VERB'),\n",
       " ('10', 'NUM'),\n",
       " ('pence', 'NOUN'),\n",
       " ('-LRB-', '.'),\n",
       " ('16', 'NUM'),\n",
       " ('cents', 'NOUN'),\n",
       " ('-RRB-', '.'),\n",
       " ('a', 'DET'),\n",
       " ('share', 'NOUN'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('close', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('879', 'NUM'),\n",
       " ('pence', 'NOUN'),\n",
       " ('-LRB-', '.'),\n",
       " ('$', '.'),\n",
       " ('13.90', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('-RRB-', '.'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('Now', 'ADV'),\n",
       " ('the', 'DET'),\n",
       " ('field', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('less', 'ADV'),\n",
       " ('cluttered', 'VERB'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('he', 'PRON'),\n",
       " ('added', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('.', '.'),\n",
       " ('Every', 'DET'),\n",
       " ('$', '.'),\n",
       " ('15,000', 'NUM'),\n",
       " ('*U*', 'X'),\n",
       " ('0', 'X'),\n",
       " ('you', 'PRON'),\n",
       " ('send', 'VERB'),\n",
       " ('*T*-1', 'X'),\n",
       " ('will', 'VERB'),\n",
       " ('go', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('long', 'ADJ'),\n",
       " ('way', 'NOUN'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('boost', 'VERB'),\n",
       " ('sagging', 'VERB'),\n",
       " ('net', 'ADJ'),\n",
       " ('worth', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('employee', 'NOUN'),\n",
       " ('morale', 'NOUN'),\n",
       " ('--', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('keep', 'VERB'),\n",
       " ('your', 'PRON'),\n",
       " ('Foster', 'NOUN'),\n",
       " ('Savings', 'NOUN'),\n",
       " ('Institution', 'NOUN'),\n",
       " ('off', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('federal', 'ADJ'),\n",
       " ('budget', 'NOUN'),\n",
       " ('deficit', 'NOUN'),\n",
       " ('!', '.'),\n",
       " ('The', 'DET'),\n",
       " ('bonds', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('insured', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('triple-A-rated', 'ADJ'),\n",
       " ('.', '.'),\n",
       " ('On', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('one', 'NUM'),\n",
       " ('hand', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Brazil', 'NOUN'),\n",
       " ('started', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('ethanol', 'NOUN'),\n",
       " ('program', 'NOUN'),\n",
       " ('about', 'ADP'),\n",
       " ('15', 'NUM'),\n",
       " ('years', 'NOUN'),\n",
       " ('ago', 'ADP'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('fuel', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('huge', 'ADJ'),\n",
       " ('portion', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('its', 'PRON'),\n",
       " ('national', 'ADJ'),\n",
       " ('fleet', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('cars', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('is', 'VERB'),\n",
       " ('now', 'ADV'),\n",
       " ('committed', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('this', 'DET'),\n",
       " ('program', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Garbage', 'NOUN'),\n",
       " ('editors', 'NOUN'),\n",
       " ('have', 'VERB'),\n",
       " ('dumped', 'VERB'),\n",
       " ('considerable', 'ADJ'),\n",
       " ('energy', 'NOUN'),\n",
       " ('into', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('whirling', 'ADJ'),\n",
       " ('rampage', 'NOUN'),\n",
       " ('through', 'ADP'),\n",
       " ('supermarket', 'NOUN'),\n",
       " ('aisles', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('bid', 'NOUN'),\n",
       " ('*', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('identify', 'VERB'),\n",
       " ('corporate', 'ADJ'),\n",
       " ('America', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('good', 'ADJ'),\n",
       " ('guys', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('bad', 'ADJ'),\n",
       " ('boys', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Dow', 'NOUN'),\n",
       " ('Jones', 'NOUN'),\n",
       " ('&', 'CONJ'),\n",
       " ('Co.', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('it', 'PRON'),\n",
       " ('extended', 'VERB'),\n",
       " ('its', 'PRON'),\n",
       " ('$', '.'),\n",
       " ('18-a-share', 'ADJ'),\n",
       " ('*U*', 'X'),\n",
       " ('offer', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('Telerate', 'NOUN'),\n",
       " ('Inc.', 'NOUN'),\n",
       " ('common', 'ADJ'),\n",
       " ('stock', 'NOUN'),\n",
       " ('until', 'ADP'),\n",
       " ('5', 'NUM'),\n",
       " ('p.m.', 'NOUN'),\n",
       " ('EST', 'NOUN'),\n",
       " ('Nov.', 'NOUN'),\n",
       " ('9', 'NUM'),\n",
       " ('.', '.'),\n",
       " ('Mrs.', 'NOUN'),\n",
       " ('Hills', 'NOUN'),\n",
       " ('said', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('still', 'ADV'),\n",
       " ('concerned', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " ('``', '.'),\n",
       " ('disturbing', 'ADJ'),\n",
       " ('developments', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Turkey', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('continuing', 'VERB'),\n",
       " ('slow', 'ADJ'),\n",
       " ('progress', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Malaysia', 'NOUN'),\n",
       " ('.', '.'),\n",
       " (\"''\", '.'),\n",
       " ('The', 'DET'),\n",
       " ('National', 'NOUN'),\n",
       " ('Association', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Diaper', 'NOUN'),\n",
       " ('Services', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Philadelphia', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('says', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('since', 'ADP'),\n",
       " ('January', 'NOUN'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('gotten', 'VERB'),\n",
       " ('more', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('672', 'NUM'),\n",
       " ('inquiries', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('people', 'NOUN'),\n",
       " ('interested', 'ADJ'),\n",
       " ('in', 'ADP'),\n",
       " ('*', 'X'),\n",
       " ('starting', 'VERB'),\n",
       " ('diaper', 'NOUN'),\n",
       " ('services', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Because', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('drought', 'NOUN'),\n",
       " ('reduced', 'VERB'),\n",
       " ('U.S.', 'NOUN'),\n",
       " ('stockpiles', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('they', 'PRON'),\n",
       " ('have', 'VERB'),\n",
       " ('more', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('enough', 'ADJ'),\n",
       " ('storage', 'NOUN'),\n",
       " ('space', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('their', 'PRON'),\n",
       " ('new', 'ADJ'),\n",
       " ('crop', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('that', 'DET'),\n",
       " ('permits', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " ('to', 'PRT'),\n",
       " ('wait', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('prices', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('rise', 'VERB'),\n",
       " ('.', '.'),\n",
       " ('``', '.'),\n",
       " ('It', 'PRON'),\n",
       " (\"'s\", 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('if', 'ADP'),\n",
       " ('France', 'NOUN'),\n",
       " ('decided', 'VERB'),\n",
       " ('*-1', 'X'),\n",
       " ('to', 'PRT'),\n",
       " ('give', 'VERB'),\n",
       " ('only', 'ADJ'),\n",
       " ('French', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " ('questions', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('students', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('European', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " ('class', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('and', 'CONJ'),\n",
       " ('when', 'ADV'),\n",
       " ('everybody', 'NOUN'),\n",
       " ('aces', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('test', 'NOUN'),\n",
       " ('*T*-3', 'X'),\n",
       " (',', '.'),\n",
       " ('they', 'PRON'),\n",
       " ('say', 'VERB'),\n",
       " ('0', 'X'),\n",
       " ('their', 'PRON'),\n",
       " ('kids', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('good', 'ADJ'),\n",
       " ('in', 'ADP'),\n",
       " ('European', 'ADJ'),\n",
       " ('history', 'NOUN'),\n",
       " (',', '.'),\n",
       " (\"''\", '.'),\n",
       " ('says', 'VERB'),\n",
       " ('*T*-2', 'X'),\n",
       " ('John', 'NOUN'),\n",
       " ('Cannell', 'NOUN'),\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S Saurabh/DT)\n"
     ]
    }
   ],
   "source": [
    "# sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),\n",
    "#             (\"dog\", \"NN\"), (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
    "sentence = [(\"Saurabh\", \"DT\")]\n",
    "grammar = \"NP_chunk: {<DT>?<NN><JJ>*}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('America', 'NNP')]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag([\"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'architect'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "wordnet_lemmatizer.lemmatize(\"architects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pos_tag in module nltk.tag:\n",
      "\n",
      "pos_tag(tokens, tagset=None, lang='eng')\n",
      "    Use NLTK's currently recommended part of speech tagger to\n",
      "    tag the given list of tokens.\n",
      "    \n",
      "        >>> from nltk.tag import pos_tag\n",
      "        >>> from nltk.tokenize import word_tokenize\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"))\n",
      "        [('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'),\n",
      "        (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal')\n",
      "        [('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'),\n",
      "        (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n",
      "    \n",
      "    NB. Use `pos_tag_sents()` for efficient tagging of more than one sentence.\n",
      "    \n",
      "    :param tokens: Sequence of tokens to be tagged\n",
      "    :type tokens: list(str)\n",
      "    :param tagset: the tagset to be used, e.g. universal, wsj, brown\n",
      "    :type tagset: str\n",
      "    :param lang: the ISO 639 code of the language, e.g. 'eng' for English, 'rus' for Russian\n",
      "    :type lang: str\n",
      "    :return: The tagged tokens\n",
      "    :rtype: list(tuple(str, str))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
